<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>03 - Voice Stack & ASR Pipeline | Cresta AI Platform Technical Assessment</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg-primary: #0f172a; --bg-secondary: #1e293b; --bg-tertiary: #334155;
            --text-primary: #f1f5f9; --text-secondary: #94a3b8; --text-muted: #64748b;
            --accent-blue: #3b82f6; --accent-cyan: #22d3ee; --accent-green: #22c55e;
            --accent-yellow: #eab308; --accent-orange: #f97316; --accent-red: #ef4444;
            --accent-purple: #a855f7; --border-color: #334155;
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body { font-family: 'Inter', sans-serif; background: var(--bg-primary); color: var(--text-primary); line-height: 1.7; font-size: 15px; }
        .container { max-width: 1400px; margin: 0 auto; padding: 40px 60px; }
        header { background: linear-gradient(135deg, var(--bg-secondary) 0%, var(--bg-tertiary) 100%); border-bottom: 1px solid var(--border-color); padding: 48px 0; }
        header .container { display: flex; justify-content: space-between; align-items: flex-start; }
        .header-content h1 { font-size: 2.25rem; font-weight: 700; margin-bottom: 8px; background: linear-gradient(135deg, var(--text-primary) 0%, var(--accent-green) 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
        .header-content .subtitle { font-size: 1.125rem; color: var(--text-secondary); }
        .doc-badge { font-family: 'JetBrains Mono', monospace; background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-cyan) 100%); padding: 8px 16px; border-radius: 8px; font-size: 0.875rem; font-weight: 600; }
        nav.doc-nav { background: var(--bg-secondary); border-bottom: 1px solid var(--border-color); padding: 12px 0; position: sticky; top: 0; z-index: 100; }
        nav.doc-nav ul { list-style: none; display: flex; gap: 6px; max-width: 1400px; margin: 0 auto; padding: 0 60px; overflow-x: auto; }
        nav.doc-nav a { color: var(--text-secondary); text-decoration: none; padding: 10px 16px; border-radius: 8px; font-size: 0.875rem; font-weight: 500; white-space: nowrap; transition: all 0.2s; }
        nav.doc-nav a:hover { background: var(--bg-tertiary); color: var(--text-primary); }
        nav.doc-nav a.active { background: linear-gradient(135deg, var(--accent-green) 0%, var(--accent-cyan) 100%); color: white; }
        section { margin-bottom: 48px; }
        h2 { font-size: 1.5rem; font-weight: 700; margin: 48px 0 24px; padding-bottom: 12px; border-bottom: 2px solid var(--border-color); display: flex; align-items: center; gap: 12px; }
        h2::before { content: ''; display: inline-block; width: 4px; height: 24px; background: linear-gradient(180deg, var(--accent-green) 0%, var(--accent-cyan) 100%); border-radius: 2px; }
        h3 { font-size: 1.125rem; font-weight: 600; margin: 32px 0 16px; color: var(--accent-cyan); }
        p { margin-bottom: 16px; color: var(--text-secondary); }
        .legend { display: flex; flex-wrap: wrap; gap: 12px; padding: 20px 24px; background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; margin-bottom: 32px; }
        .legend-item { display: flex; align-items: center; gap: 8px; font-size: 0.875rem; padding: 6px 12px; background: var(--bg-tertiary); border-radius: 6px; }
        .context-box { background: linear-gradient(135deg, rgba(34, 197, 94, 0.08) 0%, rgba(34, 211, 238, 0.08) 100%); border: 1px solid var(--border-color); border-left: 4px solid var(--accent-green); border-radius: 0 12px 12px 0; padding: 24px; margin: 24px 0; }
        .context-box strong { color: var(--accent-green); }
        .diagram-container { background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; padding: 32px; margin: 24px 0; overflow-x: auto; }
        .diagram-title { font-size: 1rem; font-weight: 600; margin-bottom: 24px; color: var(--text-primary); display: flex; align-items: center; gap: 10px; }
        .diagram-title::before { content: ''; display: inline-block; width: 4px; height: 20px; background: var(--accent-green); border-radius: 2px; }
        table { width: 100%; border-collapse: collapse; margin: 24px 0; font-size: 0.925rem; background: var(--bg-secondary); border-radius: 12px; overflow: hidden; border: 1px solid var(--border-color); }
        th, td { padding: 14px 18px; text-align: left; border-bottom: 1px solid var(--border-color); }
        th { background: var(--bg-tertiary); font-weight: 600; text-transform: uppercase; font-size: 0.75rem; letter-spacing: 0.05em; }
        tr:last-child td { border-bottom: none; }
        tr:hover td { background: rgba(34, 197, 94, 0.05); }
        .badge { display: inline-flex; align-items: center; gap: 6px; padding: 4px 10px; border-radius: 6px; font-size: 0.75rem; font-weight: 600; }
        .badge.confirmed { background: rgba(34, 197, 94, 0.15); color: var(--accent-green); }
        .badge.pending { background: rgba(234, 179, 8, 0.15); color: var(--accent-yellow); }
        .badge.high { background: rgba(239, 68, 68, 0.15); color: var(--accent-red); }
        .badge.medium { background: rgba(249, 115, 22, 0.15); color: var(--accent-orange); }
        .badge.low { background: rgba(34, 197, 94, 0.15); color: var(--accent-green); }
        .card-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 20px; margin: 24px 0; }
        .card { background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; padding: 24px; }
        .card h4 { font-size: 1rem; font-weight: 600; margin-bottom: 16px; }
        .card.latency { border-left: 4px solid var(--accent-yellow); }
        .card.operational { border-left: 4px solid var(--accent-purple); }
        .highlight-box { background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; padding: 24px; margin: 24px 0; }
        .highlight-box.info { border-left: 4px solid var(--accent-blue); }
        .highlight-box.danger { border-left: 4px solid var(--accent-red); }
        .two-col { display: grid; grid-template-columns: 1fr 1fr; gap: 24px; }
        code { font-family: 'JetBrains Mono', monospace; background: var(--bg-tertiary); padding: 2px 8px; border-radius: 4px; font-size: 0.875rem; color: var(--accent-cyan); }
        footer { background: var(--bg-secondary); border-top: 1px solid var(--border-color); padding: 32px 0; margin-top: 64px; }
        footer .container { display: flex; justify-content: space-between; font-size: 0.875rem; color: var(--text-muted); }
        @media (max-width: 1024px) { .container { padding: 24px; } nav.doc-nav ul { padding: 0 24px; } .two-col { grid-template-columns: 1fr; } }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div class="header-content">
                <h1>Voice Stack & ASR Pipeline</h1>
                <p class="subtitle">Audio Processing, Deepgram ASR Integration, and Transcript Management</p>
            </div>
            <span class="doc-badge">Document 03</span>
        </div>
    </header>

    <nav class="doc-nav">
        <ul>
            <li><a href="00-executive-summary.html">00 Summary</a></li>
            <li><a href="01-overall-architecture.html">01 Architecture</a></li>
            <li><a href="02-amazon-connect-integration.html">02 Connect</a></li>
            <li><a href="#" class="active">03 Voice Stack</a></li>
            <li><a href="04-ml-services-architecture.html">04 ML Services</a></li>
            <li><a href="05-realtime-dataflow-sequences.html">05 Data Flow</a></li>
            <li><a href="06-data-security-architecture.html">06 Security</a></li>
        </ul>
    </nav>

    <div class="container">
        <div class="legend">
            <div class="legend-item">‚è±Ô∏è Latency Risk</div>
            <div class="legend-item">üîí Security Risk</div>
            <div class="legend-item">üìã Compliance Risk</div>
            <div class="legend-item">‚öôÔ∏è Operational Risk</div>
            <div class="legend-item">üü° Requires Follow-up</div>
            <div class="legend-item">‚úÖ Confirmed</div>
        </div>

        <section>
            <h2>Voice Stack Component Architecture</h2>
            
            <div class="context-box">
                <strong>Context:</strong> The <code>gowalter</code> service receives audio via WebSocket, buffers it, and streams 20-100ms chunks to Deepgram ASR. Transcripts arrive as partials (every 0.5-1.5s) that refine over time, plus finals (every 3-7s) at sentence boundaries. An utterance builder groups these into conversation messages, which are persisted and trigger ML inference. A recovery mechanism replays buffered audio if the ASR connection drops.
            </div>

            <div class="diagram-container">
                <div class="diagram-title">Voice Processing Pipeline</div>
                <div class="mermaid">
flowchart TB
    subgraph AudioSources["Audio Sources"]
        CCaaS["CCaaS Platform<br/>(Amazon Connect)"]
        AgentApp["Agent App<br/>(Desktop Capture)"]
    end

    subgraph GoWalter["gowalter Service"]
        WSHandler["WebSocket<br/>Handler ‚è±Ô∏è"]
        AudioBuffer["Audio<br/>Buffer"]
        RecoveryMgr["Recovery<br/>Manager ‚öôÔ∏è"]
        ASRClient["ASR WebSocket<br/>Client"]
        RedactionEngine["Audio<br/>Redaction üìã"]
        AudioEncoder["Audio<br/>Encoder"]
    end

    subgraph ASRService["ASR Service - Deepgram"]
        StreamingASR["Streaming ASR ‚è±Ô∏è"]
        PartialTranscript["Partial<br/>Transcripts"]
        FinalTranscript["Final<br/>Transcripts"]
    end

    subgraph TranscriptProcessing["Transcript Processing"]
        UtteranceBuilder["Utterance<br/>Builder"]
        SpeakerDiarization["Speaker<br/>Diarization"]
    end

    subgraph APIServer["apiserver Service"]
        TranscriptUpsert["Transcript<br/>Upsert"]
        ConversationMgr["Conversation<br/>Manager"]
        EventPublisher["Event<br/>Publisher"]
    end

    subgraph DataStores["Data Storage"]
        Postgres[("PostgreSQL<br/>Transcripts")]
        S3[("S3<br/>Audio Files üîí")]
        Redis[("Redis<br/>Events")]
    end

    subgraph Downstream["Downstream Services"]
        Orchestrator["Orchestrator"]
        ClientSub["clientsubscription"]
    end

    CCaaS --> WSHandler
    AgentApp --> WSHandler
    WSHandler --> AudioBuffer
    AudioBuffer --> ASRClient
    WSHandler -.-> RecoveryMgr -.-> ASRClient
    ASRClient --> StreamingASR
    StreamingASR --> PartialTranscript
    StreamingASR --> FinalTranscript
    PartialTranscript --> UtteranceBuilder
    FinalTranscript --> UtteranceBuilder
    UtteranceBuilder --> SpeakerDiarization --> TranscriptUpsert
    TranscriptUpsert --> Postgres
    TranscriptUpsert --> ConversationMgr --> EventPublisher --> Redis
    EventPublisher --> Orchestrator
    Redis --> ClientSub
    AudioBuffer --> RedactionEngine --> AudioEncoder --> S3
                </div>
            </div>

            <h3>Voice Stack Component Reference</h3>
            <table>
                <thead>
                    <tr><th>Component</th><th>Technology</th><th>Function</th><th>Latency Impact</th><th>Status</th></tr>
                </thead>
                <tbody>
                    <tr><td><strong>gowalter</strong></td><td>Cresta Service</td><td>Audio ingestion, buffering, ASR coordination, redaction</td><td>Entry point - critical path</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>WebSocket Handler</strong></td><td>gowalter component</td><td>Receives audio streams from CCaaS or Agent App</td><td>‚è±Ô∏è Connection latency</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Audio Buffer</strong></td><td>gowalter component</td><td>Buffers audio for recovery and batching</td><td>Memory-bound</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Recovery Manager</strong></td><td>gowalter component</td><td>Replays buffered audio on ASR disconnect</td><td>‚öôÔ∏è Resilience feature</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>ASR WebSocket Client</strong></td><td>gowalter component</td><td>Manages connection to Deepgram ASR</td><td>‚è±Ô∏è Critical path</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Deepgram ASR</strong></td><td>Third-party service</td><td>Real-time speech-to-text transcription</td><td>‚è±Ô∏è 200-300ms target</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Utterance Builder</strong></td><td>gowalter/apiserver</td><td>Groups transcripts into conversation messages</td><td>Processing overhead</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Speaker Diarization</strong></td><td>Built-in</td><td>Identifies customer vs agent speech</td><td>Dual-track input</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>apiserver</strong></td><td>Cresta Service</td><td>Transcript persistence, event publishing</td><td>Database write</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Audio Redaction</strong></td><td>gowalter component</td><td>PII beeping in audio files</td><td>üìã End-of-call processing</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Audio Encoder</strong></td><td>gowalter component</td><td>Compress and encode for storage</td><td>End-of-call</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Conversation Manager</strong></td><td>apiserver component</td><td>Manages conversation state and lifecycle</td><td>‚Äî</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Event Publisher</strong></td><td>apiserver component</td><td>Publishes events to Redis for downstream</td><td>‚Äî</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>ASR Transcript Flow</h2>

            <div class="context-box">
                <strong>Context:</strong> ASR produces provisional "partial" transcripts that refine as more audio context arrives. For example, "I want to book a fight" may be corrected to "I want to book a flight" once the ASR receives more context. Finals are produced at sentence boundaries every 3-7 seconds.
            </div>

            <div class="diagram-container">
                <div class="diagram-title">Transcript Refinement Process</div>
                <div class="mermaid">
sequenceDiagram
    participant Audio as Audio Source
    participant GW as gowalter
    participant ASR as Deepgram ASR
    participant API as apiserver
    participant DB as PostgreSQL

    Note over Audio,DB: Real-time Audio Processing - Target under 300ms

    Audio->>GW: Audio chunk (20-100ms)
    activate GW
    GW->>GW: Buffer chunk
    GW-->>Audio: ACK
    deactivate GW

    GW->>ASR: Stream chunk via WebSocket
    activate ASR
    
    Note over ASR: ASR processes audio
    
    ASR-->>GW: Partial: "I want to book a fight"
    Note over GW: t=1s - provisional
    
    ASR-->>GW: Partial: "I want to book a flight to"
    Note over GW: t=2s - refined
    
    ASR-->>GW: Final: "I want to book a flight to New York"
    Note over GW: t=3s - finalized
    deactivate ASR

    GW->>API: Upsert utterance
    API->>DB: Persist transcript
    API-->>API: Publish event to Redis
                </div>
            </div>

            <h3>ASR Latency Targets</h3>
            <table>
                <thead>
                    <tr><th>Stage</th><th>Target</th><th>Actual (Confirmed)</th><th>Risk Level</th><th>Notes</th></tr>
                </thead>
                <tbody>
                    <tr><td><strong>Audio Chunk Size</strong></td><td>20-100ms</td><td>‚úì Confirmed</td><td><span class="badge low">Low</span></td><td>Sent to ASR</td></tr>
                    <tr><td><strong>ASR First Partial</strong></td><td>200-300ms</td><td>‚úì Confirmed</td><td><span class="badge high">High</span></td><td>Time to first transcript - critical path</td></tr>
                    <tr><td><strong>Partial Frequency</strong></td><td>0.5-1.5s</td><td>‚úì Confirmed</td><td><span class="badge low">Low</span></td><td>Refinement updates</td></tr>
                    <tr><td><strong>Final Chunk</strong></td><td>3-7 seconds</td><td>‚úì Confirmed</td><td><span class="badge low">Low</span></td><td>Complete sentence boundary</td></tr>
                    <tr><td><strong>Utterance to Agent App</strong></td><td>~1 second</td><td>‚úì Confirmed</td><td><span class="badge medium">Medium</span></td><td>Real-time display update</td></tr>
                    <tr><td><strong>End-to-End (Audio ‚Üí Guidance)</strong></td><td>&lt;1.5s</td><td>‚úì Confirmed</td><td><span class="badge high">High</span></td><td>Total real-time path</td></tr>
                </tbody>
            </table>

            <h3>Transcript Refinement Example</h3>
            <table>
                <thead>
                    <tr><th>Time</th><th>Type</th><th>Transcript</th><th>Action</th></tr>
                </thead>
                <tbody>
                    <tr><td>t=0.5s</td><td>Partial</td><td>"I want"</td><td>Provisional - display with low confidence</td></tr>
                    <tr><td>t=1.0s</td><td>Partial</td><td>"I want to book a fight"</td><td>Update display - still provisional</td></tr>
                    <tr><td>t=1.5s</td><td>Partial</td><td>"I want to book a flight"</td><td>Corrected - higher confidence</td></tr>
                    <tr><td>t=2.0s</td><td>Partial</td><td>"I want to book a flight to"</td><td>Continue building utterance</td></tr>
                    <tr><td>t=3.5s</td><td>Final</td><td>"I want to book a flight to New York"</td><td>Finalized - trigger ML inference</td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Recovery Mechanism</h2>

            <div class="context-box">
                <strong>Context:</strong> The gowalter service maintains an audio buffer to handle ASR connection failures. If the WebSocket to Deepgram drops, gowalter automatically reconnects and replays buffered audio to catch up transcription, ensuring no audio is lost during temporary disconnections.
            </div>

            <div class="diagram-container">
                <div class="diagram-title">WebSocket Recovery Flow</div>
                <div class="mermaid">
sequenceDiagram
    participant Connect as Amazon Connect
    participant GW as gowalter
    participant Buffer as Audio Buffer
    participant ASR as Deepgram ASR

    Note over Connect,ASR: Normal Operation
    Connect->>GW: Audio stream
    GW->>Buffer: Store chunks
    GW->>ASR: Forward audio
    ASR-->>GW: Transcripts

    Note over GW,ASR: ‚ö†Ô∏è ASR Connection Lost
    ASR--xGW: WebSocket disconnected

    rect rgb(50, 50, 70)
        Note right of GW: Recovery Sequence
        GW->>GW: Detect disconnect
        GW->>ASR: Reconnect WebSocket
        GW->>Buffer: Get buffered audio
        GW->>ASR: Replay buffered chunks
        ASR-->>GW: Catch-up transcripts
    end

    Note over Connect,ASR: Service Restored
    Connect->>GW: Continue stream
    GW->>ASR: Resume normal flow
                </div>
            </div>

            <div class="highlight-box info">
                <h3>Recovery Mechanism Details</h3>
                <p>The gowalter service maintains an audio buffer to handle ASR connection failures. Key behaviors:</p>
                <ul style="padding-left: 24px; color: var(--text-secondary); line-height: 1.8;">
                    <li><strong>Buffer Size:</strong> üü° Verify - exact buffer duration unknown (likely 30-60 seconds)</li>
                    <li><strong>Reconnection:</strong> Automatic WebSocket reconnection with exponential backoff</li>
                    <li><strong>Replay:</strong> Buffered audio chunks are replayed in order to catch up transcription</li>
                    <li><strong>Max Retries:</strong> üü° Verify - specific retry count unknown (likely 3-5 attempts)</li>
                    <li><strong>Failure Mode:</strong> On max retries exceeded, gap is logged and transcript marked incomplete</li>
                    <li><strong>Performance:</strong> Recovery typically completes within 2-5 seconds of reconnection</li>
                </ul>
            </div>

            <h3>Recovery Scenarios</h3>
            <table>
                <thead><tr><th>Scenario</th><th>Buffer State</th><th>Recovery Action</th><th>Impact</th></tr></thead>
                <tbody>
                    <tr><td>Brief disconnect (&lt;10s)</td><td>Full buffer available</td><td>Replay all missed audio</td><td>No transcript gaps</td></tr>
                    <tr><td>Extended disconnect (10-60s)</td><td>Partial buffer</td><td>Replay available audio, mark gap</td><td>Transcript gap noted</td></tr>
                    <tr><td>Long disconnect (&gt;60s)</td><td>Buffer overflow</td><td>Resume from reconnection point</td><td>Transcript loss logged</td></tr>
                    <tr><td>Max retries exceeded</td><td>Buffer preserved</td><td>Log error, notify operations</td><td>Call continues without transcripts</td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>End-of-Call Processing</h2>

            <div class="diagram-container">
                <div class="diagram-title">Audio Redaction & Storage Flow</div>
                <div class="mermaid">
flowchart TB
    subgraph CallEnd["Call Termination"]
        CloseEvent["CloseConversation<br/>Event"]
    end

    subgraph GoWalterProcess["gowalter Processing"]
        Encode["Encode Audio<br/>(Compression)"]
        PIIDetect["PII Detection üìã"]
        AudioRedact["Apply Audio<br/>Beeps"]
        Upload["Upload to S3 üîí"]
    end

    subgraph APIServerProcess["apiserver Processing"]
        IndexES["Index in<br/>Elasticsearch"]
        StoreAnalytics["Store in<br/>ClickHouse"]
        TriggerSummary["Trigger<br/>Summarization"]
        TemporalWorkflow["Temporal Workflow<br/>(Verify Redaction) ‚öôÔ∏è"]
    end

    subgraph Verification["Redaction Verification"]
        DoubleCheck["Re-scan for<br/>Unredacted PII"]
        Decision{PII Found?}
        Retry["Retry<br/>Redaction"]
        Complete["Mark<br/>Complete"]
        Alert["Page<br/>On-Call ‚öôÔ∏è"]
    end

    CloseEvent --> Encode --> PIIDetect --> AudioRedact --> Upload
    CloseEvent --> IndexES
    CloseEvent --> StoreAnalytics
    CloseEvent --> TriggerSummary
    CloseEvent --> TemporalWorkflow

    TemporalWorkflow --> DoubleCheck --> Decision
    Decision -->|Yes| Retry --> DoubleCheck
    Decision -->|No| Complete
    Retry -->|Max Retries| Alert
                </div>
            </div>

            <h3>End-of-Call Processing Components</h3>
            <table>
                <thead>
                    <tr><th>Process</th><th>Service</th><th>Description</th><th>Duration</th><th>Status</th></tr>
                </thead>
                <tbody>
                    <tr><td><strong>Audio Encoding</strong></td><td>gowalter</td><td>Compress and encode audio for storage</td><td>2-5 seconds</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>PII Detection</strong></td><td>gowalter</td><td>Identify SSN, credit cards, names in audio</td><td>3-10 seconds</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Audio Redaction</strong></td><td>gowalter</td><td>Apply beep tones over detected PII</td><td>2-5 seconds</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>S3 Upload</strong></td><td>gowalter</td><td>Upload redacted audio to encrypted S3</td><td>5-15 seconds</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>ES Indexing</strong></td><td>apiserver</td><td>Index conversation for search</td><td>1-2 seconds</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Analytics Storage</strong></td><td>apiserver</td><td>Store metrics in ClickHouse</td><td>1-2 seconds</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Summarization</strong></td><td>apiserver ‚Üí ML</td><td>Generate call summary via Ocean-1</td><td>3-8 seconds</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Redaction Verification</strong></td><td>Temporal</td><td>Re-scan to ensure no PII remains</td><td>5-15 seconds</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                </tbody>
            </table>

            <h3>PII Detection Methods</h3>
            <table>
                <thead><tr><th>PII Type</th><th>Detection Method</th><th>Audio Redaction</th><th>Text Redaction</th></tr></thead>
                <tbody>
                    <tr><td><strong>Full Names</strong></td><td>NER Model</td><td>Beep tone</td><td>[FULLNAME]</td></tr>
                    <tr><td><strong>SSN</strong></td><td>Regex + ML confidence</td><td>Beep tone</td><td>[SSN]</td></tr>
                    <tr><td><strong>Credit Card</strong></td><td>Luhn algorithm + regex</td><td>Beep tone</td><td>[CREDITCARD]</td></tr>
                    <tr><td><strong>Phone Numbers</strong></td><td>Regex patterns</td><td>Beep tone</td><td>[PHONE]</td></tr>
                    <tr><td><strong>Email Addresses</strong></td><td>Regex patterns</td><td>Beep tone</td><td>[EMAIL]</td></tr>
                    <tr><td><strong>Addresses</strong></td><td>NER Model</td><td>Beep tone</td><td>[ADDRESS]</td></tr>
                    <tr><td><strong>Date of Birth</strong></td><td>Context + regex</td><td>Beep tone</td><td>[DOB]</td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Deepgram ASR Integration</h2>

            <h3>Deepgram Configuration</h3>
            <table>
                <thead><tr><th>Parameter</th><th>Value</th><th>Description</th><th>Impact</th></tr></thead>
                <tbody>
                    <tr><td><strong>Model</strong></td><td>Nova-2 (likely)</td><td>Latest generation streaming model</td><td>Accuracy and speed</td></tr>
                    <tr><td><strong>Language</strong></td><td>en-US (default)</td><td>Can be overridden per call</td><td>üü° Multi-language support TBD</td></tr>
                    <tr><td><strong>Sample Rate</strong></td><td>8000 Hz</td><td>Matches Amazon Connect KVS</td><td>No resampling needed</td></tr>
                    <tr><td><strong>Encoding</strong></td><td>linear16</td><td>PCM 16-bit</td><td>Standard telephony</td></tr>
                    <tr><td><strong>Channels</strong></td><td>1 (mono per track)</td><td>Separate streams per speaker</td><td>Speaker diarization</td></tr>
                    <tr><td><strong>Interim Results</strong></td><td>true</td><td>Enable partial transcripts</td><td>Real-time display</td></tr>
                    <tr><td><strong>Punctuation</strong></td><td>true</td><td>Automatic punctuation</td><td>Readability</td></tr>
                    <tr><td><strong>Diarization</strong></td><td>false</td><td>Handled via dual-track</td><td>Pre-separated audio</td></tr>
                    <tr><td><strong>Smart Format</strong></td><td>true</td><td>Format numbers, dates, times</td><td>Improved readability</td></tr>
                </tbody>
            </table>

            <h3>Deepgram Performance Characteristics</h3>
            <table>
                <thead><tr><th>Metric</th><th>Specification</th><th>Source</th></tr></thead>
                <tbody>
                    <tr><td><strong>Time to First Transcript</strong></td><td>200-300ms</td><td>‚úì Cresta Blog</td></tr>
                    <tr><td><strong>Word Error Rate (WER)</strong></td><td>&lt;10% (telephony)</td><td>‚úì Deepgram Docs</td></tr>
                    <tr><td><strong>Supported Languages</strong></td><td>36+ languages</td><td>‚úì Deepgram Docs</td></tr>
                    <tr><td><strong>Uptime SLA</strong></td><td>99.9%</td><td>‚úì Deepgram Docs</td></tr>
                    <tr><td><strong>Concurrent Connections</strong></td><td>Unlimited (with scaling)</td><td>‚úì Deepgram Docs</td></tr>
                    <tr><td><strong>Audio Format Support</strong></td><td>PCM, MP3, WAV, FLAC, etc.</td><td>‚úì Deepgram Docs</td></tr>
                </tbody>
            </table>

            <h3>Alternative ASR Providers üü°</h3>
            <table>
                <thead><tr><th>Provider</th><th>Advantages</th><th>Disadvantages</th><th>Status</th></tr></thead>
                <tbody>
                    <tr><td><strong>Amazon Transcribe</strong></td><td>AWS native, no egress, easy integration</td><td>Higher latency (~1-2s), lower accuracy for telephony</td><td><span class="badge pending">üü° Verify support</span></td></tr>
                    <tr><td><strong>Google Speech-to-Text</strong></td><td>High accuracy, 125+ languages</td><td>GCP dependency, cost, latency</td><td><span class="badge pending">üü° Verify support</span></td></tr>
                    <tr><td><strong>Assembly AI</strong></td><td>Modern API, good accuracy</td><td>Less proven at scale</td><td><span class="badge pending">üü° Verify support</span></td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Risk Assessment</h2>
            <div class="two-col">
                <div class="card latency">
                    <h4>‚è±Ô∏è Latency Risks</h4>
                    <table>
                        <tr><td>ASR WebSocket</td><td><span class="badge high">High</span></td><td>Connection instability impacts transcription</td></tr>
                        <tr><td>Audio Buffering</td><td><span class="badge medium">Medium</span></td><td>Memory pressure under high load</td></tr>
                        <tr><td>Network Jitter</td><td><span class="badge medium">Medium</span></td><td>Variable chunk delivery timing</td></tr>
                        <tr><td>Deepgram Service</td><td><span class="badge high">High</span></td><td>External dependency for critical path</td></tr>
                    </table>
                    <p style="margin-top: 16px; font-size: 0.875rem;"><strong>Mitigation:</strong> Recovery mechanism, adaptive buffering, connection pooling, regional Deepgram endpoints</p>
                </div>
                <div class="card operational">
                    <h4>‚öôÔ∏è Operational Risks</h4>
                    <table>
                        <tr><td>Deepgram Availability</td><td><span class="badge pending">üü° Verify</span></td><td>ASR provider outage impact</td></tr>
                        <tr><td>Buffer Overflow</td><td><span class="badge low">Low</span></td><td>High concurrent calls</td></tr>
                        <tr><td>Redaction Failures</td><td><span class="badge low">Low</span></td><td>Temporal verification catches issues</td></tr>
                        <tr><td>S3 Upload Failures</td><td><span class="badge low">Low</span></td><td>S3 durability 99.999999999%</td></tr>
                    </table>
                    <p style="margin-top: 16px; font-size: 0.875rem;"><strong>Mitigation:</strong> Fallback ASR (üü° verify), auto-scaling, Temporal workflows, retry logic</p>
                </div>
            </div>
        </section>

        <section>
            <h2>Performance Monitoring</h2>

            <h3>Key Metrics to Track</h3>
            <table>
                <thead><tr><th>Metric</th><th>Target</th><th>Alert Threshold</th><th>Action</th></tr></thead>
                <tbody>
                    <tr><td><strong>ASR First Partial Latency</strong></td><td>&lt;300ms</td><td>&gt;500ms for 5+ consecutive calls</td><td>Check Deepgram service status</td></tr>
                    <tr><td><strong>WebSocket Connection Drops</strong></td><td>&lt;0.1%</td><td>&gt;1% of calls</td><td>Review network stability</td></tr>
                    <tr><td><strong>Buffer Overflow Events</strong></td><td>0</td><td>Any occurrence</td><td>Increase buffer size or concurrency</td></tr>
                    <tr><td><strong>Audio Upload Failures</strong></td><td>&lt;0.01%</td><td>&gt;0.1%</td><td>Check S3 configuration and IAM</td></tr>
                    <tr><td><strong>PII Redaction Failures</strong></td><td>0</td><td>Any occurrence</td><td>Page on-call immediately</td></tr>
                    <tr><td><strong>Transcript Accuracy (WER)</strong></td><td>&lt;10%</td><td>&gt;15%</td><td>Review sample calls, consider model tuning</td></tr>
                    <tr><td><strong>Recovery Success Rate</strong></td><td>&gt;99%</td><td>&lt;95%</td><td>Review recovery logic and retry counts</td></tr>
                </tbody>
            </table>

            <h3>Logging and Observability</h3>
            <table>
                <thead><tr><th>Log Type</th><th>Content</th><th>Retention</th><th>Purpose</th></tr></thead>
                <tbody>
                    <tr><td><strong>Audio Stream Logs</strong></td><td>Connection events, chunk sizes, timestamps</td><td>30 days</td><td>Debug latency issues</td></tr>
                    <tr><td><strong>ASR Request/Response</strong></td><td>Partial/final transcripts, confidence scores</td><td>30 days</td><td>Accuracy analysis</td></tr>
                    <tr><td><strong>Recovery Events</strong></td><td>Disconnect/reconnect, buffer replay actions</td><td>90 days</td><td>Reliability tracking</td></tr>
                    <tr><td><strong>PII Detection</strong></td><td>Detected types, redaction actions (not actual PII)</td><td>1 year</td><td>Compliance auditing</td></tr>
                    <tr><td><strong>Error Logs</strong></td><td>All exceptions and failures</td><td>90 days</td><td>Root cause analysis</td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Items Requiring Follow-up üü°</h2>
            <div class="highlight-box danger">
                <h4>üî¥ High Priority</h4>
                <ol style="padding-left: 20px; color: var(--text-secondary); line-height: 1.8;">
                    <li><strong>ASR Provider Selection:</strong> Is Deepgram the only ASR provider or are there alternatives (Amazon Transcribe, Google STT)? What is the failover plan if Deepgram is unavailable?</li>
                    <li><strong>Audio Buffer Size:</strong> What is the exact buffer duration maintained by gowalter for recovery? How is buffer size determined (time-based or memory-based)?</li>
                    <li><strong>Multi-Language Support:</strong> How is language detection and switching handled? Are multilingual conversations supported on a single call?</li>
                    <li><strong>Audio Format Details:</strong> Exact codec specifications from Amazon Connect KVS - confirmed 8kHz PCM but verify bit depth and any compression.</li>
                    <li><strong>ASR Failover:</strong> What happens if Deepgram is completely unavailable? Is there a backup ASR provider or does the call continue without transcription?</li>
                </ol>
            </div>

            <div class="highlight-box info">
                <h4>üü° Medium Priority</h4>
                <ol start="6" style="padding-left: 20px; color: var(--text-secondary); line-height: 1.8;">
                    <li><strong>Recovery Retry Logic:</strong> Specific retry counts and backoff strategy for ASR reconnection.</li>
                    <li><strong>Deepgram SLA:</strong> What is the contractual SLA with Deepgram? Regional availability?</li>
                    <li><strong>Audio Quality Monitoring:</strong> How is audio quality (SNR, packet loss) monitored and addressed?</li>
                    <li><strong>Transcript Confidence Scores:</strong> Are confidence scores exposed to downstream ML models? How are low-confidence transcripts handled?</li>
                    <li><strong>Custom Vocabulary:</strong> Can customer-specific vocabulary (product names, technical terms) be added to improve ASR accuracy?</li>
                </ol>
            </div>
        </section>
    </div>

    <footer>
        <div class="container">
            <div>Cresta AI Platform Assessment - Document 03: Voice Stack & ASR Pipeline</div>
            <div>January 2025 | Version 2.0</div>
        </div>
    </footer>

    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'dark',
            themeVariables: {
                primaryColor: '#22c55e', primaryTextColor: '#f1f5f9', primaryBorderColor: '#334155',
                lineColor: '#64748b', secondaryColor: '#1e293b', tertiaryColor: '#0f172a',
                background: '#1e293b', mainBkg: '#1e293b', nodeBorder: '#334155',
                clusterBkg: '#1e293b', clusterBorder: '#475569'
            },
            flowchart: { useMaxWidth: true, htmlLabels: true, curve: 'basis' },
            sequence: { useMaxWidth: true },
            securityLevel: 'loose'
        });
    </script>
</body>
</html>
