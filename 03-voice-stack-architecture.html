<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>03 - Voice Stack Architecture | Cresta AI Platform Assessment</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;500;600;700&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root { --bg-primary: #0a0f1a; --bg-secondary: #111827; --bg-tertiary: #1f2937; --text-primary: #f3f4f6; --text-secondary: #9ca3af; --accent-blue: #3b82f6; --accent-cyan: #06b6d4; --accent-green: #10b981; --accent-yellow: #f59e0b; --accent-red: #ef4444; --accent-purple: #8b5cf6; --border-color: #374151; }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body { font-family: 'IBM Plex Sans', -apple-system, sans-serif; background: var(--bg-primary); color: var(--text-primary); line-height: 1.7; }
        .container { max-width: 1400px; margin: 0 auto; padding: 40px 60px; }
        header { background: linear-gradient(135deg, var(--bg-secondary) 0%, var(--bg-tertiary) 100%); border-bottom: 1px solid var(--border-color); padding: 40px 0; }
        header .container { display: flex; justify-content: space-between; align-items: center; }
        .breadcrumb { font-size: 0.875rem; color: var(--text-secondary); margin-bottom: 8px; }
        .breadcrumb a { color: var(--accent-cyan); text-decoration: none; }
        header h1 { font-size: 2rem; font-weight: 700; }
        .doc-num { font-family: 'IBM Plex Mono', monospace; background: var(--accent-green); padding: 4px 12px; border-radius: 4px; font-size: 0.875rem; }
        nav.doc-nav { background: var(--bg-secondary); border-bottom: 1px solid var(--border-color); padding: 16px 0; position: sticky; top: 0; z-index: 100; }
        nav.doc-nav ul { list-style: none; display: flex; gap: 8px; max-width: 1400px; margin: 0 auto; padding: 0 60px; overflow-x: auto; }
        nav.doc-nav a { color: var(--text-secondary); text-decoration: none; padding: 8px 16px; border-radius: 6px; font-size: 0.875rem; white-space: nowrap; transition: all 0.2s; }
        nav.doc-nav a:hover { background: var(--bg-tertiary); color: var(--text-primary); }
        nav.doc-nav a.active { background: var(--accent-green); color: white; }
        section { margin-bottom: 48px; }
        h2 { font-size: 1.5rem; font-weight: 600; margin: 40px 0 24px; padding-bottom: 12px; border-bottom: 2px solid var(--border-color); }
        h3 { font-size: 1.125rem; font-weight: 600; margin: 24px 0 16px; color: var(--accent-cyan); }
        p { margin-bottom: 16px; color: var(--text-secondary); }
        .context-box { background: linear-gradient(135deg, rgba(16, 185, 129, 0.1) 0%, rgba(6, 182, 212, 0.1) 100%); border: 1px solid var(--border-color); border-left: 4px solid var(--accent-green); border-radius: 0 12px 12px 0; padding: 24px; margin: 24px 0; }
        .context-box strong { color: var(--accent-green); }
        .diagram-container { background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; padding: 32px; margin: 24px 0; overflow-x: auto; }
        .diagram-title { font-size: 1rem; font-weight: 600; margin-bottom: 20px; color: var(--text-primary); display: flex; align-items: center; gap: 8px; }
        .diagram-title::before { content: ''; display: inline-block; width: 4px; height: 20px; background: var(--accent-green); border-radius: 2px; }
        table { width: 100%; border-collapse: collapse; margin: 24px 0; font-size: 0.95rem; }
        th, td { padding: 14px 16px; text-align: left; border-bottom: 1px solid var(--border-color); }
        th { background: var(--bg-tertiary); font-weight: 600; text-transform: uppercase; font-size: 0.75rem; letter-spacing: 0.05em; }
        tr:hover td { background: rgba(16, 185, 129, 0.05); }
        .badge { display: inline-flex; align-items: center; gap: 6px; padding: 4px 10px; border-radius: 6px; font-size: 0.75rem; font-weight: 500; }
        .badge.confirmed { background: rgba(16, 185, 129, 0.15); color: var(--accent-green); }
        .badge.pending { background: rgba(245, 158, 11, 0.15); color: var(--accent-yellow); }
        .badge.high { background: rgba(239, 68, 68, 0.15); color: var(--accent-red); }
        .badge.medium { background: rgba(245, 158, 11, 0.15); color: var(--accent-yellow); }
        .badge.low { background: rgba(16, 185, 129, 0.15); color: var(--accent-green); }
        .highlight-box { background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; padding: 24px; margin: 24px 0; }
        .highlight-box.warning { border-left: 4px solid var(--accent-yellow); }
        .highlight-box.info { border-left: 4px solid var(--accent-blue); }
        .highlight-box.danger { border-left: 4px solid var(--accent-red); }
        .two-col { display: grid; grid-template-columns: 1fr 1fr; gap: 24px; }
        code { font-family: 'IBM Plex Mono', monospace; background: var(--bg-tertiary); padding: 2px 8px; border-radius: 4px; font-size: 0.875rem; }
        .legend { display: flex; flex-wrap: wrap; gap: 16px; padding: 20px; background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; margin-bottom: 24px; }
        .legend-item { display: flex; align-items: center; gap: 8px; font-size: 0.875rem; }
        .risk-box { background: var(--bg-secondary); border: 1px solid var(--border-color); border-radius: 12px; padding: 24px; margin: 16px 0; }
        .risk-box h4 { font-size: 1rem; margin-bottom: 16px; }
        .risk-box.latency { border-left: 4px solid var(--accent-yellow); }
        .risk-box.operational { border-left: 4px solid var(--accent-purple); }
        footer { background: var(--bg-secondary); border-top: 1px solid var(--border-color); padding: 40px 0; margin-top: 60px; }
        footer .container { display: flex; justify-content: space-between; font-size: 0.875rem; color: var(--text-secondary); }
        @media (max-width: 900px) { .two-col { grid-template-columns: 1fr; } .container { padding: 20px; } }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <div>
                <div class="breadcrumb"><a href="00-executive-summary.html">‚Üê Back to Executive Summary</a></div>
                <h1>Voice Stack & ASR Pipeline</h1>
            </div>
            <span class="doc-num">Document 03</span>
        </div>
    </header>

    <nav class="doc-nav">
        <ul>
            <li><a href="00-executive-summary.html">00 Summary</a></li>
            <li><a href="01-overall-architecture.html">01 Architecture</a></li>
            <li><a href="02-amazon-connect-integration.html">02 Connect</a></li>
            <li><a href="03-voice-stack-architecture.html" class="active">03 Voice</a></li>
            <li><a href="04-ml-services-architecture.html">04 ML</a></li>
            <li><a href="05-realtime-dataflow-sequences.html">05 Data Flow</a></li>
            <li><a href="06-data-security-architecture.html">06 Security</a></li>
        </ul>
    </nav>

    <div class="container">
        <div class="legend">
            <div class="legend-item">‚è±Ô∏è Latency Risk</div>
            <div class="legend-item">üîí Security Risk</div>
            <div class="legend-item">üìã Compliance Risk</div>
            <div class="legend-item">‚öôÔ∏è Operational Risk</div>
            <div class="legend-item">üü° Requires Follow-up</div>
        </div>

        <section>
            <h2>Voice Stack Component Architecture</h2>
            
            <div class="context-box">
                <strong>Context:</strong> The <code>gowalter</code> service receives audio via WebSocket, buffers it, and streams 20-100ms chunks to Deepgram ASR. Transcripts arrive as partials (every 0.5-1.5s) that refine over time, plus finals (every 3-7s) at sentence boundaries. An utterance builder groups these into conversation messages, which are persisted and trigger ML inference. A recovery mechanism replays buffered audio if the ASR connection drops.
            </div>

            <div class="diagram-container">
                <div class="diagram-title">Voice Processing Pipeline</div>
                <div class="mermaid">
flowchart TB
    subgraph AudioSources["Audio Sources"]
        CCaaS["CCaaS Platform<br/>(Amazon Connect)"]
        AgentApp["Agent App<br/>(Desktop Capture)"]
    end

    subgraph GoWalter["gowalter Service"]
        WSHandler["WebSocket<br/>Handler ‚è±Ô∏è"]
        AudioBuffer["Audio<br/>Buffer"]
        RecoveryMgr["Recovery<br/>Manager ‚öôÔ∏è"]
        ASRClient["ASR WebSocket<br/>Client"]
        RedactionEngine["Audio<br/>Redaction üìã"]
        AudioEncoder["Audio<br/>Encoder"]
    end

    subgraph ASRService["ASR Service - Deepgram"]
        StreamingASR["Streaming ASR ‚è±Ô∏è"]
        PartialTranscript["Partial<br/>Transcripts"]
        FinalTranscript["Final<br/>Transcripts"]
    end

    subgraph TranscriptProcessing["Transcript Processing"]
        UtteranceBuilder["Utterance<br/>Builder"]
        SpeakerDiarization["Speaker<br/>Diarization"]
    end

    subgraph APIServer["apiserver Service"]
        TranscriptUpsert["Transcript<br/>Upsert"]
        ConversationMgr["Conversation<br/>Manager"]
        EventPublisher["Event<br/>Publisher"]
    end

    subgraph DataStores["Data Storage"]
        Postgres[("PostgreSQL<br/>Transcripts")]
        S3[("S3<br/>Audio Files üîí")]
        Redis[("Redis<br/>Events")]
    end

    subgraph Downstream["Downstream Services"]
        Orchestrator["Orchestrator"]
        ClientSub["clientsubscription"]
    end

    CCaaS --> WSHandler
    AgentApp --> WSHandler
    WSHandler --> AudioBuffer
    AudioBuffer --> ASRClient
    WSHandler -.-> RecoveryMgr -.-> ASRClient
    ASRClient --> StreamingASR
    StreamingASR --> PartialTranscript
    StreamingASR --> FinalTranscript
    PartialTranscript --> UtteranceBuilder
    FinalTranscript --> UtteranceBuilder
    UtteranceBuilder --> SpeakerDiarization --> TranscriptUpsert
    TranscriptUpsert --> Postgres
    TranscriptUpsert --> ConversationMgr --> EventPublisher --> Redis
    EventPublisher --> Orchestrator
    Redis --> ClientSub
    AudioBuffer --> RedactionEngine --> AudioEncoder --> S3
                </div>
            </div>

            <h3>Voice Stack Component Reference</h3>
            <table>
                <thead>
                    <tr><th>Component</th><th>Technology</th><th>Function</th><th>Latency Impact</th><th>Status</th></tr>
                </thead>
                <tbody>
                    <tr><td><strong>gowalter</strong></td><td>Cresta Service</td><td>Audio ingestion, buffering, ASR coordination, redaction</td><td>Entry point - critical path</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>WebSocket Handler</strong></td><td>gowalter component</td><td>Receives audio streams from CCaaS or Agent App</td><td>‚è±Ô∏è Connection latency</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Audio Buffer</strong></td><td>gowalter component</td><td>Buffers audio for recovery and batching</td><td>Memory-bound</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Recovery Manager</strong></td><td>gowalter component</td><td>Replays buffered audio on ASR disconnect</td><td>‚öôÔ∏è Resilience feature</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Deepgram ASR</strong></td><td>Third-party service</td><td>Real-time speech-to-text transcription</td><td>‚è±Ô∏è 200-300ms target</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Utterance Builder</strong></td><td>gowalter/apiserver</td><td>Groups transcripts into conversation messages</td><td>Processing overhead</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Speaker Diarization</strong></td><td>Built-in</td><td>Identifies customer vs agent speech</td><td>Dual-track input</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>apiserver</strong></td><td>Cresta Service</td><td>Transcript persistence, event publishing</td><td>Database write</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Audio Redaction</strong></td><td>gowalter component</td><td>PII beeping in audio files</td><td>üìã End-of-call processing</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>ASR Transcript Flow</h2>

            <div class="context-box">
                <strong>Context:</strong> ASR produces provisional "partial" transcripts that refine as more audio context arrives. For example, "I want to book a fight" may be corrected to "I want to book a flight" once the ASR receives more context. Finals are produced at sentence boundaries every 3-7 seconds.
            </div>

            <div class="diagram-container">
                <div class="diagram-title">Transcript Refinement Process</div>
                <div class="mermaid">
sequenceDiagram
    participant Audio as Audio Source
    participant GW as gowalter
    participant ASR as Deepgram ASR
    participant API as apiserver
    participant DB as PostgreSQL

    Note over Audio,DB: Real-time Audio Processing - Target under 300ms

    Audio->>GW: Audio chunk (20-100ms)
    activate GW
    GW->>GW: Buffer chunk
    GW-->>Audio: ACK
    deactivate GW

    GW->>ASR: Stream chunk via WebSocket
    activate ASR
    
    Note over ASR: ASR processes audio
    
    ASR-->>GW: Partial: "I want to book a fight"
    Note over GW: t=1s - provisional
    
    ASR-->>GW: Partial: "I want to book a flight to"
    Note over GW: t=2s - refined
    
    ASR-->>GW: Final: "I want to book a flight to New York"
    Note over GW: t=3s - finalized
    deactivate ASR

    GW->>API: Upsert utterance
    API->>DB: Persist transcript
    API-->>API: Publish event to Redis
                </div>
            </div>

            <h3>ASR Latency Targets</h3>
            <table>
                <thead>
                    <tr><th>Stage</th><th>Target</th><th>Actual (Confirmed)</th><th>Risk Level</th><th>Notes</th></tr>
                </thead>
                <tbody>
                    <tr><td><strong>Audio Chunk Size</strong></td><td>20-100ms</td><td>‚úì Confirmed</td><td><span class="badge low">Low</span></td><td>Sent to ASR</td></tr>
                    <tr><td><strong>ASR First Partial</strong></td><td>200-300ms</td><td>‚úì Confirmed</td><td><span class="badge high">High</span></td><td>Time to first transcript - critical path</td></tr>
                    <tr><td><strong>Final Chunk</strong></td><td>3-7 seconds</td><td>‚úì Confirmed</td><td><span class="badge low">Low</span></td><td>Complete sentence boundary</td></tr>
                    <tr><td><strong>Utterance to Agent App</strong></td><td>~1 second</td><td>‚úì Confirmed</td><td><span class="badge medium">Medium</span></td><td>Real-time display update</td></tr>
                    <tr><td><strong>End-to-End (Audio ‚Üí Guidance)</strong></td><td>&lt;1.5s</td><td>‚úì Confirmed</td><td><span class="badge high">High</span></td><td>Total real-time path</td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Recovery Mechanism</h2>

            <div class="diagram-container">
                <div class="diagram-title">WebSocket Recovery Flow</div>
                <div class="mermaid">
sequenceDiagram
    participant Connect as Amazon Connect
    participant GW as gowalter
    participant Buffer as Audio Buffer
    participant ASR as Deepgram ASR

    Note over Connect,ASR: Normal Operation
    Connect->>GW: Audio stream
    GW->>Buffer: Store chunks
    GW->>ASR: Forward audio
    ASR-->>GW: Transcripts

    Note over GW,ASR: ‚ö†Ô∏è ASR Connection Lost
    ASR--xGW: WebSocket disconnected

    rect rgb(50, 50, 70)
        Note right of GW: Recovery Sequence
        GW->>GW: Detect disconnect
        GW->>ASR: Reconnect WebSocket
        GW->>Buffer: Get buffered audio
        GW->>ASR: Replay buffered chunks
        ASR-->>GW: Catch-up transcripts
    end

    Note over Connect,ASR: Service Restored
    Connect->>GW: Continue stream
    GW->>ASR: Resume normal flow
                </div>
            </div>

            <div class="highlight-box info">
                <h3>Recovery Mechanism Details</h3>
                <p>The gowalter service maintains an audio buffer to handle ASR connection failures. Key behaviors:</p>
                <ul style="padding-left: 24px; color: var(--text-secondary);">
                    <li><strong>Buffer Size:</strong> üü° Verify - exact buffer duration unknown</li>
                    <li><strong>Reconnection:</strong> Automatic WebSocket reconnection with retry logic</li>
                    <li><strong>Replay:</strong> Buffered audio chunks are replayed to catch up transcription</li>
                    <li><strong>Max Retries:</strong> üü° Verify - specific retry count unknown</li>
                    <li><strong>Failure Mode:</strong> On max retries exceeded, gap is logged and transcript marked incomplete</li>
                </ul>
            </div>
        </section>

        <section>
            <h2>End-of-Call Processing</h2>

            <div class="diagram-container">
                <div class="diagram-title">Audio Redaction & Storage Flow</div>
                <div class="mermaid">
flowchart TB
    subgraph CallEnd["Call Termination"]
        CloseEvent["CloseConversation<br/>Event"]
    end

    subgraph GoWalterProcess["gowalter Processing"]
        Encode["Encode Audio<br/>(Compression)"]
        PIIDetect["PII Detection üìã"]
        AudioRedact["Apply Audio<br/>Beeps"]
        Upload["Upload to S3 üîí"]
    end

    subgraph APIServerProcess["apiserver Processing"]
        IndexES["Index in<br/>Elasticsearch"]
        StoreAnalytics["Store in<br/>ClickHouse"]
        TriggerSummary["Trigger<br/>Summarization"]
        TemporalWorkflow["Temporal Workflow<br/>(Verify Redaction) ‚öôÔ∏è"]
    end

    subgraph Verification["Redaction Verification"]
        DoubleCheck["Re-scan for<br/>Unredacted PII"]
        Decision{PII Found?}
        Retry["Retry<br/>Redaction"]
        Complete["Mark<br/>Complete"]
        Alert["Page<br/>On-Call ‚öôÔ∏è"]
    end

    CloseEvent --> Encode --> PIIDetect --> AudioRedact --> Upload
    CloseEvent --> IndexES
    CloseEvent --> StoreAnalytics
    CloseEvent --> TriggerSummary
    CloseEvent --> TemporalWorkflow

    TemporalWorkflow --> DoubleCheck --> Decision
    Decision -->|Yes| Retry --> DoubleCheck
    Decision -->|No| Complete
    Retry -->|Max Retries| Alert
                </div>
            </div>

            <h3>End-of-Call Processing Components</h3>
            <table>
                <thead>
                    <tr><th>Process</th><th>Service</th><th>Description</th><th>Status</th></tr>
                </thead>
                <tbody>
                    <tr><td><strong>Audio Encoding</strong></td><td>gowalter</td><td>Compress and encode audio for storage</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>PII Detection</strong></td><td>gowalter</td><td>Identify SSN, credit cards, names in audio</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Audio Redaction</strong></td><td>gowalter</td><td>Apply beep tones over detected PII</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>S3 Upload</strong></td><td>gowalter</td><td>Upload redacted audio to encrypted S3</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>ES Indexing</strong></td><td>apiserver</td><td>Index conversation for search</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Analytics Storage</strong></td><td>apiserver</td><td>Store metrics in ClickHouse</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Summarization</strong></td><td>apiserver ‚Üí ML</td><td>Generate call summary via Ocean-1</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                    <tr><td><strong>Redaction Verification</strong></td><td>Temporal</td><td>Re-scan to ensure no PII remains</td><td><span class="badge confirmed">‚úì Confirmed</span></td></tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Risk Assessment</h2>
            <div class="two-col">
                <div class="risk-box latency">
                    <h4>‚è±Ô∏è Latency Risks</h4>
                    <table>
                        <tr><td>ASR WebSocket</td><td><span class="badge high">High</span></td><td>Connection instability impacts transcription</td></tr>
                        <tr><td>Audio Buffering</td><td><span class="badge medium">Medium</span></td><td>Memory pressure under high load</td></tr>
                        <tr><td>Network Jitter</td><td><span class="badge medium">Medium</span></td><td>Variable chunk delivery timing</td></tr>
                    </table>
                    <p style="margin-top: 16px; font-size: 0.875rem;"><strong>Mitigation:</strong> Recovery mechanism, adaptive buffering, connection pooling</p>
                </div>
                <div class="risk-box operational">
                    <h4>‚öôÔ∏è Operational Risks</h4>
                    <table>
                        <tr><td>Deepgram Availability</td><td><span class="badge pending">üü° Verify</span></td><td>ASR provider outage impact</td></tr>
                        <tr><td>Buffer Overflow</td><td><span class="badge low">Low</span></td><td>High concurrent calls</td></tr>
                        <tr><td>Redaction Failures</td><td><span class="badge low">Low</span></td><td>Temporal verification catches issues</td></tr>
                    </table>
                    <p style="margin-top: 16px; font-size: 0.875rem;"><strong>Mitigation:</strong> Fallback ASR (üü° verify), auto-scaling, Temporal workflows</p>
                </div>
            </div>
        </section>

        <section>
            <h2>Items Requiring Follow-up üü°</h2>
            <div class="highlight-box danger">
                <ol style="padding-left: 20px; color: var(--text-secondary);">
                    <li><strong>ASR Provider Selection:</strong> Is Deepgram the only ASR or are there alternatives (Amazon Transcribe)?</li>
                    <li><strong>Audio Format:</strong> Exact codec and sample rate from Amazon Connect KVS</li>
                    <li><strong>Buffer Size Limits:</strong> How much audio is buffered for recovery?</li>
                    <li><strong>Multi-Language Support:</strong> How is language detection handled for ASR?</li>
                    <li><strong>ASR Failover:</strong> What happens if Deepgram is unavailable?</li>
                </ol>
            </div>
        </section>
    </div>

    <footer>
        <div class="container">
            <div>Cresta AI Platform Assessment - Document 03: Voice Stack Architecture</div>
            <div>Generated: January 2025</div>
        </div>
    </footer>

    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'dark',
            themeVariables: { primaryColor: '#10b981', primaryTextColor: '#f3f4f6', primaryBorderColor: '#374151', lineColor: '#6b7280', secondaryColor: '#1f2937', tertiaryColor: '#111827', background: '#111827', mainBkg: '#1f2937', nodeBorder: '#374151', clusterBkg: '#1f2937', clusterBorder: '#374151' },
            flowchart: { useMaxWidth: true, htmlLabels: true, curve: 'basis' },
            sequence: { useMaxWidth: true },
            securityLevel: 'loose'
        });
    </script>
</body>
</html>
